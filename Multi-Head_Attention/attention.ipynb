{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as f\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(128, 32, 512)\n",
    "d_model = 512\n",
    "n_head = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_head):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_head = n_head\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # TODO self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.w_combine = nn.Linear(d_model, d_model)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        batch, time, dimension = q.shape\n",
    "        n_d = self.d_model//self.n_head\n",
    "        q, k, v = self.w_q(q), self.w_k(k), self.w_v(v)\n",
    "\n",
    "        q = q.view(batch, time, self.n_head, n_d).permute(0, 2, 1, 3)\n",
    "        k = k.view(batch, time, self.n_head, n_d).permute(0, 2, 1, 3)\n",
    "        v = v.view(batch, time, self.n_head, n_d).permute(0, 2, 1, 3)\n",
    "\n",
    "        score = q @ k.transpose(2,3)/math.sqrt(n_d)\n",
    "\n",
    "        # 是否使用掩码\n",
    "        if mask is not None:\n",
    "            score = score.masked_fill(mask==0, -10000)\n",
    "        score = self.softmax(score)@v\n",
    "        # 将加权值重新排列\n",
    "        score = score.permute(0, 2, 1, 3).contiguous().view(batch, time, dimension)\n",
    "        output = self.w_combine(score)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实际应用\n",
    "attention = MultiHeadAttention(d_model, n_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-5.7451e-01, -5.1952e-02, -4.4980e-02,  ..., -1.2093e+00,\n",
      "           5.3894e-01, -1.5803e+00],\n",
      "         [-5.1599e-01, -1.0537e-01, -1.0344e-01,  ..., -1.2566e+00,\n",
      "           4.8568e-01, -1.5943e+00],\n",
      "         [-6.2014e-01, -5.2003e-02, -8.1265e-02,  ..., -1.2228e+00,\n",
      "           5.4199e-01, -1.5605e+00],\n",
      "         ...,\n",
      "         [-6.3748e-01, -8.8462e-02, -1.0768e-01,  ..., -1.2628e+00,\n",
      "           6.0105e-01, -1.5460e+00],\n",
      "         [-5.8561e-01, -4.9528e-02, -3.4395e-02,  ..., -1.1627e+00,\n",
      "           6.0745e-01, -1.5965e+00],\n",
      "         [-5.5127e-01, -6.0567e-03,  4.3767e-02,  ..., -1.1436e+00,\n",
      "           5.2303e-01, -1.5795e+00]],\n",
      "\n",
      "        [[-5.2106e-01, -3.0776e-03, -4.0464e-01,  ..., -1.2116e+00,\n",
      "           4.3165e-01, -1.6808e+00],\n",
      "         [-5.6568e-01,  3.1164e-02, -3.6846e-01,  ..., -1.1646e+00,\n",
      "           4.6545e-01, -1.5898e+00],\n",
      "         [-5.5567e-01,  1.8965e-02, -3.3534e-01,  ..., -1.1327e+00,\n",
      "           5.3946e-01, -1.6865e+00],\n",
      "         ...,\n",
      "         [-5.9939e-01,  3.7426e-02, -3.8127e-01,  ..., -1.1199e+00,\n",
      "           4.9582e-01, -1.6242e+00],\n",
      "         [-5.5239e-01,  6.7739e-03, -3.3707e-01,  ..., -1.1854e+00,\n",
      "           5.1775e-01, -1.6385e+00],\n",
      "         [-5.6894e-01,  1.4342e-02, -3.8340e-01,  ..., -1.1578e+00,\n",
      "           4.9691e-01, -1.6343e+00]],\n",
      "\n",
      "        [[-4.4253e-01, -1.2233e-01, -2.5707e-01,  ..., -1.1495e+00,\n",
      "           5.4243e-01, -1.6535e+00],\n",
      "         [-4.4098e-01, -1.4669e-01, -2.7188e-01,  ..., -1.2106e+00,\n",
      "           5.3069e-01, -1.6775e+00],\n",
      "         [-4.2398e-01, -1.2734e-01, -2.6438e-01,  ..., -1.1879e+00,\n",
      "           4.4428e-01, -1.5906e+00],\n",
      "         ...,\n",
      "         [-3.8265e-01, -1.4772e-01, -2.8509e-01,  ..., -1.2010e+00,\n",
      "           4.5444e-01, -1.6540e+00],\n",
      "         [-4.0824e-01, -1.5886e-01, -3.0271e-01,  ..., -1.2039e+00,\n",
      "           4.9495e-01, -1.6671e+00],\n",
      "         [-4.6982e-01, -1.5518e-01, -2.9563e-01,  ..., -1.2156e+00,\n",
      "           5.4908e-01, -1.6524e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4.4648e-01,  5.8278e-03, -1.5763e-01,  ..., -1.2437e+00,\n",
      "           5.7618e-01, -1.5790e+00],\n",
      "         [-5.1294e-01, -4.5621e-02, -3.3849e-01,  ..., -1.3198e+00,\n",
      "           5.6797e-01, -1.5763e+00],\n",
      "         [-4.7382e-01,  5.7155e-03, -2.2490e-01,  ..., -1.2726e+00,\n",
      "           5.5969e-01, -1.5848e+00],\n",
      "         ...,\n",
      "         [-5.1151e-01, -9.3962e-03, -2.3444e-01,  ..., -1.2869e+00,\n",
      "           6.1004e-01, -1.6096e+00],\n",
      "         [-4.6553e-01, -2.1269e-02, -2.5157e-01,  ..., -1.3174e+00,\n",
      "           5.3803e-01, -1.6015e+00],\n",
      "         [-4.9523e-01, -2.5541e-02, -2.6417e-01,  ..., -1.2923e+00,\n",
      "           5.8648e-01, -1.5871e+00]],\n",
      "\n",
      "        [[-4.4012e-01, -1.4425e-01, -2.8446e-01,  ..., -1.2142e+00,\n",
      "           4.4918e-01, -1.6651e+00],\n",
      "         [-3.8113e-01, -1.0017e-01, -2.3734e-01,  ..., -1.1195e+00,\n",
      "           4.4377e-01, -1.6774e+00],\n",
      "         [-4.4729e-01, -1.3037e-01, -2.7859e-01,  ..., -1.1749e+00,\n",
      "           5.0201e-01, -1.6663e+00],\n",
      "         ...,\n",
      "         [-4.2140e-01, -1.4556e-01, -2.7040e-01,  ..., -1.2335e+00,\n",
      "           4.5923e-01, -1.6947e+00],\n",
      "         [-4.3470e-01, -1.1720e-01, -2.5067e-01,  ..., -1.1126e+00,\n",
      "           4.9785e-01, -1.6428e+00],\n",
      "         [-3.6532e-01, -1.5787e-01, -2.8956e-01,  ..., -1.1823e+00,\n",
      "           3.9069e-01, -1.6452e+00]],\n",
      "\n",
      "        [[-4.8480e-01,  1.7237e-02, -2.4944e-01,  ..., -1.2598e+00,\n",
      "           5.1559e-01, -1.7675e+00],\n",
      "         [-5.0875e-01,  3.4436e-03, -2.3590e-01,  ..., -1.3260e+00,\n",
      "           4.8952e-01, -1.7841e+00],\n",
      "         [-4.8932e-01,  9.9400e-04, -2.9013e-01,  ..., -1.3478e+00,\n",
      "           4.2540e-01, -1.7998e+00],\n",
      "         ...,\n",
      "         [-4.2833e-01,  2.9808e-02, -2.2123e-01,  ..., -1.2452e+00,\n",
      "           4.2021e-01, -1.7355e+00],\n",
      "         [-4.3275e-01, -1.9137e-02, -3.0856e-01,  ..., -1.3563e+00,\n",
      "           4.1698e-01, -1.8192e+00],\n",
      "         [-4.1075e-01,  3.4517e-02, -2.5527e-01,  ..., -1.2144e+00,\n",
      "           3.9301e-01, -1.7398e+00]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out = attention(x, x, x)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
